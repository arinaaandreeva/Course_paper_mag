{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":11305158,"sourceType":"competition"},{"sourceId":9801075,"sourceType":"datasetVersion","datasetId":6006872},{"sourceId":9806342,"sourceType":"datasetVersion","datasetId":6010899},{"sourceId":203900450,"sourceType":"kernelVersion"},{"sourceId":214068676,"sourceType":"kernelVersion"},{"sourceId":171905,"sourceType":"modelInstanceVersion","modelInstanceId":146319,"modelId":168862},{"sourceId":183967,"sourceType":"modelInstanceVersion","modelInstanceId":156796,"modelId":179231}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":80.344101,"end_time":"2024-10-26T03:27:42.952247","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-26T03:26:22.608146","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"252dd2de87de42f4becd877fbbafc26b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff55584ae0ab4f39ae471f314eaad988","placeholder":"​","style":"IPY_MODEL_b8d338c473aa4dc3ba25f37a997a9037","value":" 1/1 [00:00&lt;00:00, 33.79it/s]"}},"48a2731fb59b4ce8ace5b53d6f0e3337":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8dbc79c7c5a48318466a102c55801bb","placeholder":"​","style":"IPY_MODEL_ebd06aaaa7024a1684ba1b9fe89358cf","value":"100%"}},"56da652f3eeb42aca986e6fd815629dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bb4e0df01c44716afebab25aafe9f5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4e41234b0cc4f3e9313d971f5aadc9f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6408698650f74dd699bcc914b850e396","value":1}},"6408698650f74dd699bcc914b850e396":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9cb493ec04fc4ed391f5ac28cc84500e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48a2731fb59b4ce8ace5b53d6f0e3337","IPY_MODEL_5bb4e0df01c44716afebab25aafe9f5f","IPY_MODEL_252dd2de87de42f4becd877fbbafc26b"],"layout":"IPY_MODEL_56da652f3eeb42aca986e6fd815629dc"}},"a8dbc79c7c5a48318466a102c55801bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8d338c473aa4dc3ba25f37a997a9037":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebd06aaaa7024a1684ba1b9fe89358cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4e41234b0cc4f3e9313d971f5aadc9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff55584ae0ab4f39ae471f314eaad988":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv, pd.read_parquet )\nimport polars as pl\n\nimport os, gc\nfrom tqdm.auto import tqdm\nimport pickle # module to serialize and deserialize objects\nimport re # for Regular expression operations \n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data  import Dataset, DataLoader\nfrom pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingRegressor\n\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Lasso\n#from sklearn import svm \nimport xgboost as xgb\nfrom sklearn.linear_model import BayesianRidge,Ridge\nimport random\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns = None\n\nimport kaggle_evaluation.jane_street_inference_server","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:23.413179Z","iopub.execute_input":"2024-12-01T21:19:23.413544Z","iopub.status.idle":"2024-12-01T21:19:23.421443Z","shell.execute_reply.started":"2024-12-01T21:19:23.413494Z","shell.execute_reply":"2024-12-01T21:19:23.42039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\npath = \"/kaggle/input/jane-street-real-time-market-data-forecasting\"\n# samples = [] \n\n# Load a data from each file:\n# r = range(8,10)\n# for i in r:\n#     file_path = f\"{path}/train.parquet/partition_id={i}/part-0.parquet\"\n#     part = pd.read_parquet(file_path)\n#     samples.append(part)\n    \n#sample_df = pd.concat(samples, ignore_index=True) # Concatenate all samples into one DataFrame if needed\n\n#sample_df.round(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:23.566959Z","iopub.execute_input":"2024-12-01T21:19:23.567705Z","iopub.status.idle":"2024-12-01T21:19:23.574106Z","shell.execute_reply.started":"2024-12-01T21:19:23.567649Z","shell.execute_reply":"2024-12-01T21:19:23.572974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# numerical_features=[]\n# numerical_features=sample_df.filter(regex='^responder_').columns.tolist() # Separate responders\n# numerical_features.remove('responder_6')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:23.796471Z","iopub.execute_input":"2024-12-01T21:19:23.797223Z","iopub.status.idle":"2024-12-01T21:19:23.801955Z","shell.execute_reply.started":"2024-12-01T21:19:23.797178Z","shell.execute_reply":"2024-12-01T21:19:23.800953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ENSEMBLE_SOLUTIONS = ['SOLUTION_14','SOLUTION_5']\nOPTION,__WTS = 'option 91',[0.89, 0.28]\n# 0,988","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:23.943526Z","iopub.execute_input":"2024-12-01T21:19:23.943872Z","iopub.status.idle":"2024-12-01T21:19:23.948304Z","shell.execute_reply.started":"2024-12-01T21:19:23.943842Z","shell.execute_reply":"2024-12-01T21:19:23.947417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(test:pl.DataFrame, lags:pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:    \n    pdB = predict_14(test,lags).to_pandas() # pred are lower then in C\n    pdC = predict_5(test,lags).to_pandas() \n\n    pdB = pdB.rename(columns={'responder_6':'responder_B'})\n    pdC = pdC.rename(columns={'responder_6':'responder_C'})\n    pds = pd.merge(pdB,pdC, on=['row_id'])\n    pds['responder_6'] =\\\n        pds['responder_B'] *__WTS[0] +\\\n        pds['responder_C'] *__WTS[1] \n\n    display(pds)\n    predictions = test.select('row_id', pl.lit(0.0).alias('responder_6'))\n    pred = pds['responder_6'].to_numpy()\n    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n    return predictions","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:24.104022Z","iopub.execute_input":"2024-12-01T21:19:24.104375Z","iopub.status.idle":"2024-12-01T21:19:24.110745Z","shell.execute_reply.started":"2024-12-01T21:19:24.104344Z","shell.execute_reply":"2024-12-01T21:19:24.109675Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" 5. [JS Ridge baseline](https://www.kaggle.com/code/yunsuxiaozi/js-ridge-baseline) Lb=0.0026\n [yunsuxiaozi](https://www.kaggle.com/yunsuxiaozi)","metadata":{"papermill":{"duration":0.022173,"end_time":"2024-10-26T03:27:39.285949","exception":false,"start_time":"2024-10-26T03:27:39.263776","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Ridge","metadata":{}},{"cell_type":"markdown","source":"Обучение модели","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n\n    \n    def seed_everything(seed):\n        np.random.seed(seed)\n        random.seed(seed)\n        \n    seed_everything(seed=2024)\n    \n    def custom_metric(y_true,y_pred,weight):\n        weighted_r2=1-(np.sum(weight*(y_true-y_pred)**2)/np.sum(weight*y_true**2))\n        return weighted_r2\n\n    print(\"read data\")\n\n    train=pl.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=9/part-0.parquet\")\n    train=train.to_pandas()\n\n    print(\"get X,y\")\n\n    cols=[f'feature_0{i}' if i<10 else f'feature_{i}' for i in range(79)]\n    X=train[cols].fillna(3).values\n    y=train['responder_6'].values\n    print(\"train test split\")\n    split=1300000#大约是8:2\n    weights=train['weight'].values\n    train_X,train_y,test_X,test_y,train_weight,test_weight=X[:-split],y[:-split],X[-split:],y[-split:],weights[:-split],weights[-split:]\n    print(f\"train_X.shape:{train_X.shape},test_X.shape:{test_X.shape}\")\n    print(\"fit and predict\")\n    model_5 = BayesianRidge()\n    model_5.fit(train_X,train_y)\n    train_pred = model_5.predict(train_X)\n    test_pred  = model_5.predict(test_X)\n    print(f\"train weighted_r2:{custom_metric(train_y, train_pred, weight=train_weight)}\")\n    print(f\"test weighted_r2: {custom_metric(test_y,  test_pred,  weight= test_weight)}\")\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:24.35874Z","iopub.execute_input":"2024-12-01T21:19:24.359126Z","iopub.status.idle":"2024-12-01T21:19:24.364012Z","shell.execute_reply.started":"2024-12-01T21:19:24.359097Z","shell.execute_reply":"2024-12-01T21:19:24.363045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import joblib\n# joblib.dump(model_5, 'ridge_b.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:24.51Z","iopub.execute_input":"2024-12-01T21:19:24.510891Z","iopub.status.idle":"2024-12-01T21:19:24.514698Z","shell.execute_reply.started":"2024-12-01T21:19:24.51084Z","shell.execute_reply":"2024-12-01T21:19:24.513783Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Скачивание готовой модели","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    def predict_5(test,lags):\n        cols=[f'feature_0{i}' if i<10 else f'feature_{i}' for i in range(79)]\n        predictions = test.select(\n            'row_id',\n            pl.lit(0.0).alias('responder_6'),\n        )\n        test_preds=model_5.predict(test[cols].to_pandas().fillna(3).values)\n        predictions = predictions.with_columns(pl.Series('responder_6', test_preds.ravel()))\n        return predictions\n\nif 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    from sklearn.linear_model import BayesianRidge\n    import joblib\n    model_5 = joblib.load('/kaggle/input/jane-street-5-and-7_/other/default/1/ridge_model_5(1).pkl')","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.031534,"end_time":"2024-10-26T03:27:39.453592","exception":false,"start_time":"2024-10-26T03:27:39.422058","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:24.813089Z","iopub.execute_input":"2024-12-01T21:19:24.815272Z","iopub.status.idle":"2024-12-01T21:19:24.831848Z","shell.execute_reply.started":"2024-12-01T21:19:24.815212Z","shell.execute_reply":"2024-12-01T21:19:24.830821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"14. [Jane Street RMF NN + XGB](https://www.kaggle.com/code/voix97/jane-street-rmf-nn-xgb), Lb=0.0056\n [Xiang Sheng](https://www.kaggle.com/voix97)","metadata":{}},{"cell_type":"markdown","source":"### NN + XGB inference\n\n### Configurations","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:    \n    \n    class CONFIG:\n        seed = 42\n        target_col = \"responder_6\"\n        feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n        feature_ridge = [f'feature_0{i}' if i<10 else f'feature_{i}' for i in range(79)]\n        model_paths = [\n            \"/kaggle/input/js-xs-nn-trained-model\",\n            \"/kaggle/input/js-with-lags-trained-xgb/result.pkl\",\n        ]\n\nif 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    valid = pl.scan_parquet(\n        f\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet/\"\n    ).collect().to_pandas()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:25.26424Z","iopub.execute_input":"2024-12-01T21:19:25.264876Z","iopub.status.idle":"2024-12-01T21:19:26.08738Z","shell.execute_reply.started":"2024-12-01T21:19:25.26484Z","shell.execute_reply":"2024-12-01T21:19:26.08666Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load model","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS: \n    \n    xgb_model = None\n    model_path = CONFIG.model_paths[1]\n    with open( model_path, \"rb\") as fp:\n        result = pickle.load(fp)\n        xgb_model = result[\"model\"]\n\n    xgb_feature_cols = [\"symbol_id\", \"time_id\"] + CONFIG.feature_cols\n\n    # Show model\n    #display(xgb_model)\n\nif 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    # Custom R2 metric for validation\n    def r2_val(y_true, y_pred, sample_weight):\n        r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n        return r2\n\n\n    class NN(LightningModule):\n        def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n            super().__init__()\n            self.save_hyperparameters()\n            layers = []\n            in_dim = input_dim\n            for i, hidden_dim in enumerate(hidden_dims):\n                layers.append(nn.BatchNorm1d(in_dim))\n                if i > 0:\n                    layers.append(nn.SiLU())\n                if i < len(dropouts):\n                    layers.append(nn.Dropout(dropouts[i]))\n                layers.append(nn.Linear(in_dim, hidden_dim))\n                # layers.append(nn.ReLU())\n                in_dim = hidden_dim\n            layers.append(nn.Linear(in_dim, 1))  \n            layers.append(nn.Tanh())\n            self.model = nn.Sequential(*layers)\n            self.lr = lr\n            self.weight_decay = weight_decay\n            self.validation_step_outputs = []\n\n        def forward(self, x):\n            return 5 * self.model(x).squeeze(-1)  \n\n        def training_step(self, batch):\n            x, y, w = batch\n            y_hat = self(x)\n            loss = F.mse_loss(y_hat, y, reduction='none') * w  \n            loss = loss.mean()\n            self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n            return loss\n\n        def validation_step(self, batch):\n            x, y, w = batch\n            y_hat = self(x)\n            loss = F.mse_loss(y_hat, y, reduction='none') * w\n            loss = loss.mean()\n            self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n            self.validation_step_outputs.append((y_hat, y, w))\n            return loss\n\n        def on_validation_epoch_end(self):\n            \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n            y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n            if self.trainer.sanity_checking:\n                prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n            else:\n                prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n                weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n                # r2_val\n                val_r_square = r2_val(y, prob, weights)\n                self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n            self.validation_step_outputs.clear()\n\n        def configure_optimizers(self):\n            optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n                                                                   verbose=True)\n            return {\n                'optimizer': optimizer,\n                'lr_scheduler': {\n                    'scheduler': scheduler,\n                    'monitor': 'val_loss',\n                }\n            }\n\n        def on_train_epoch_end(self):\n            if self.trainer.sanity_checking:\n                return\n            epoch = self.trainer.current_epoch\n            metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n            formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n            print(f\"Epoch {epoch}: {formatted_metrics}\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:26.088948Z","iopub.execute_input":"2024-12-01T21:19:26.089229Z","iopub.status.idle":"2024-12-01T21:19:26.114649Z","shell.execute_reply.started":"2024-12-01T21:19:26.089203Z","shell.execute_reply":"2024-12-01T21:19:26.113378Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    N_folds = 5\n    models = []\n    for fold in range(N_folds):\n        checkpoint_path = f\"{CONFIG.model_paths[0]}/nn_{fold}.model\"\n        model = NN.load_from_checkpoint(checkpoint_path) #, strict=False\n        models.append(model.to(\"cuda:0\"))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:26.116004Z","iopub.execute_input":"2024-12-01T21:19:26.116596Z","iopub.status.idle":"2024-12-01T21:19:26.370844Z","shell.execute_reply.started":"2024-12-01T21:19:26.116544Z","shell.execute_reply":"2024-12-01T21:19:26.369918Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CV Score","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    valid = pl.scan_parquet(\n        f\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet/\"\n    ).collect().to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:26.78709Z","iopub.execute_input":"2024-12-01T21:19:26.787362Z","iopub.status.idle":"2024-12-01T21:19:26.791367Z","shell.execute_reply.started":"2024-12-01T21:19:26.787337Z","shell.execute_reply":"2024-12-01T21:19:26.79031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS: \n    X_valid = valid[ xgb_feature_cols ]\n    y_valid = valid[ CONFIG.target_col ]\n    w_valid = valid[ \"weight\" ]\n    y_pred_valid_xgb = xgb_model.predict(X_valid)\n    #y_pred_valid_xgb = y_pred_valid_xgb + (y_pred_valid_xgb * w_valid).sum()/ w_valid.sum()\n    #y_pred_valid_xgb = y_pred_valid_xgb + y_pred_valid_xgb.mean()\n    valid_score = r2_score( y_valid, y_pred_valid_xgb, sample_weight=w_valid )\n    valid_score","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:26.953975Z","iopub.execute_input":"2024-12-01T21:19:26.9547Z","iopub.status.idle":"2024-12-01T21:19:26.958241Z","shell.execute_reply.started":"2024-12-01T21:19:26.954657Z","shell.execute_reply":"2024-12-01T21:19:26.957258Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    X_valid = valid[ CONFIG.feature_cols ]\n    y_valid = valid[ CONFIG.target_col ]\n    w_valid = valid[ \"weight\" ]\n    X_valid = X_valid.fillna(method = 'ffill').fillna(0)\n    X_valid.shape, y_valid.shape, w_valid.shape\n\nif 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    y_pred_valid_nn = np.zeros(y_valid.shape)\n    with torch.no_grad():\n        for model in models:\n            model.eval()\n            y_pred_valid_nn += model(torch.FloatTensor(X_valid.values).to(\"cuda:0\")).cpu().numpy() / len(models)\n    valid_score = r2_score( y_valid, y_pred_valid_nn, sample_weight=w_valid )\n    valid_score\n\nif 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    #y_pred_valid_ensemble = 0.5 * (y_pred_valid_xgb + y_pred_valid_nn)\n    # print('XGB: ', y_pred_valid_xgb.mean(), 'NN: ', y_pred_valid_nn.mean())\n    # print('XGB median: ', np.median(y_pred_valid_xgb), 'NN median: ', np.median(y_pred_valid_nn))\n    y_pred_valid_ensemble = 0.65 * y_pred_valid_xgb + 0.35*y_pred_valid_nn \n    #print('Ensemble: ', y_pred_valid_ensemble.mean())\n    #print('Ensemble median: ', np.median(y_pred_valid_ensemble))\n    #y_pred_valid_ensemble = y_pred_valid_ensemble -(y_pred_valid_ensemble * w_valid).sum()/ w_valid.sum()\n    #(y_pred_valid_ensemble).mean()\n    valid_score = r2_score( y_valid, y_pred_valid_ensemble, sample_weight=w_valid )\n    valid_score\n\nif 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    X_valid = valid[CONFIG.feature_ridge]\n    y_valid = valid[CONFIG.target_col]\n    w_valid = valid[ \"weight\" ] \n    X_valid = X_valid.fillna(method = 'ffill').fillna(0)\n    X_valid.shape, y_valid.shape, w_valid.shape\n    y_pred_valid_ridge = model_5.predict(X_valid.fillna(method = 'ffill').values)\n    y_pred_valid_ensemble = y_pred_valid_ensemble * 0.98 + 0.28*y_pred_valid_ridge\n    y_pred_valid_ensemble = y_pred_valid_ensemble - (y_pred_valid_ensemble * w_valid).sum()/w_valid.sum()\n    valid_score = r2_score( y_valid, y_pred_valid_ensemble, sample_weight=w_valid )\n    valid_score\n\nif 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    del valid, X_valid, y_valid, w_valid\n    gc.collect()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:27.112549Z","iopub.execute_input":"2024-12-01T21:19:27.113245Z","iopub.status.idle":"2024-12-01T21:19:27.117594Z","shell.execute_reply.started":"2024-12-01T21:19:27.113218Z","shell.execute_reply":"2024-12-01T21:19:27.116575Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# valid_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:27.266875Z","iopub.execute_input":"2024-12-01T21:19:27.267122Z","iopub.status.idle":"2024-12-01T21:19:27.270792Z","shell.execute_reply.started":"2024-12-01T21:19:27.267098Z","shell.execute_reply":"2024-12-01T21:19:27.269881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Scores in validation for different post_processing\n\n# 0.01131019 score for ensemble_pred - weighted avg(ensemble_pred) (0.35xgb+0.55nn)\n# 0.01188395 score for ensemble_pred - weighted avg(ensemble_pred) (0.4xgb+0.6nn)\n# 0.01199055 score for ensemble_pred - weighted avg(ensemble_pred) (0.5 weights for xgb+nn)\n# 0.01201276 score for pred_xgb + avg(pred_xgb)\n# 0.01201298 score for pred_xgb + weighted avg(pred_xgb)\n# 0.01202971 score for pred_xgb + meadian(pred_xgb)\n# 0.01202981 score for usual predictions\n# 0.01204447 score for pred_xgb - weighted avg(pred_xgb)\n# 0.01204464 score for pred_xgb - avg(pred_xgb)\n# 0.01206211 score for pred_ensamble - avg(pred_ensamble)\n# 0.01211081 score 0.6 xgb +0.4 nn - avg(pred)\n# 0.01211419 score 0.65 xgb +0.35 nn - avg(pred)\n# Лучше чуть увеличить вес бустинга в ансамбле\n# Вычитание среднего предсказания ансамбля, а среднее отриц. => итог. предсказание д.б. больше  \n\n# 0.01185643 сейчас для 0.5 весов и без пост-обработки\n# 0.01206463  ensemble 0.95 + 0.28ridge\n# 0.01217069 ensemble 0.98 + 0.28ridge  \n# 0.01230881 ensemble 0.98 + 0.28ridge - weighted avg(pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:27.691949Z","iopub.execute_input":"2024-12-01T21:19:27.692504Z","iopub.status.idle":"2024-12-01T21:19:27.696509Z","shell.execute_reply.started":"2024-12-01T21:19:27.692473Z","shell.execute_reply":"2024-12-01T21:19:27.695614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:    \n    \n    lags_ : pl.DataFrame | None = None\n\n    def predict_14(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n        global lags_\n        if lags is not None:\n            lags_ = lags\n\n        predictions_14 = test.select(\n            'row_id',\n            pl.lit(0.0).alias('responder_6'),\n        )\n        symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n\n        if not lags is None:\n            lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n            test = test.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n        else:\n            test = test.with_columns(\n                ( pl.lit(0.0).alias(f'responder_{idx}_lag_1') for idx in range(9) )\n            )\n\n        preds = np.zeros((test.shape[0],))\n        preds += 0.65*xgb_model.predict(test[xgb_feature_cols].to_pandas()) / 2\n        test_input = test[CONFIG.feature_cols].to_pandas()\n        test_input = test_input.fillna(method = 'ffill').fillna(0)\n        test_input = torch.FloatTensor(test_input.values).to(\"cuda:0\")\n        with torch.no_grad():\n            for i, nn_model in enumerate(tqdm(models)):\n                nn_model.eval()\n                preds += 0.35*nn_model(test_input).cpu().numpy() / 10\n        print(f\"predict> preds.shape =\", preds.shape)\n\n        predictions_14 = \\\n        test.select('row_id').\\\n        with_columns(\n            pl.Series(\n                name   = 'responder_6', \n                values = np.clip(preds-preds.mean(), a_min = -5, a_max = 5),\n                dtype  = pl.Float64,\n            )\n        )\n\n        # The predict function must return a DataFrame\n        #assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n        # with columns 'row_id', 'responer_6'\n        #assert list(predictions.columns) == ['row_id', 'responder_6']\n        # and as many rows as the test data.\n        #assert len(predictions) == len(test)\n\n        return predictions_14","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:19:28.085351Z","iopub.execute_input":"2024-12-01T21:19:28.085722Z","iopub.status.idle":"2024-12-01T21:19:28.094287Z","shell.execute_reply.started":"2024-12-01T21:19:28.085689Z","shell.execute_reply":"2024-12-01T21:19:28.093254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"papermill":{"duration":0.351292,"end_time":"2024-10-26T03:27:42.101707","exception":false,"start_time":"2024-10-26T03:27:41.750415","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-12-01T21:19:28.649107Z","iopub.execute_input":"2024-12-01T21:19:28.649673Z","iopub.status.idle":"2024-12-01T21:19:28.820848Z","shell.execute_reply.started":"2024-12-01T21:19:28.649639Z","shell.execute_reply":"2024-12-01T21:19:28.819776Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
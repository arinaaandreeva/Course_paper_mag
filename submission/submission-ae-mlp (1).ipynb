{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":169851,"sourceType":"modelInstanceVersion","modelInstanceId":144507,"modelId":167068},{"sourceId":169928,"sourceType":"modelInstanceVersion","modelInstanceId":144567,"modelId":167129},{"sourceId":169990,"sourceType":"modelInstanceVersion","modelInstanceId":144620,"modelId":167181},{"sourceId":191664,"sourceType":"modelInstanceVersion","modelInstanceId":163370,"modelId":185731},{"sourceId":191687,"sourceType":"modelInstanceVersion","modelInstanceId":163391,"modelId":185754},{"sourceId":191903,"sourceType":"modelInstanceVersion","modelInstanceId":163595,"modelId":185954},{"sourceId":191938,"sourceType":"modelInstanceVersion","modelInstanceId":163630,"modelId":185989},{"sourceId":205603,"sourceType":"modelInstanceVersion","modelInstanceId":175344,"modelId":197693},{"sourceId":205605,"sourceType":"modelInstanceVersion","modelInstanceId":175346,"modelId":197695},{"sourceId":206072,"sourceType":"modelInstanceVersion","modelInstanceId":175730,"modelId":198074},{"sourceId":220368,"sourceType":"modelInstanceVersion","modelInstanceId":187942,"modelId":209985},{"sourceId":220370,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":187944,"modelId":209987},{"sourceId":221815,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":189194,"modelId":211200}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom joblib import load\nimport polars as pl\nimport kaggle_evaluation.jane_street_inference_server\nimport gc\nimport lightgbm as lgb\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, WeightedRandomSampler, TensorDataset\nfrom tqdm.auto import tqdm\n# import tensorflow as tf\n# from tensorflow.keras import layers, models\n\nimport os\n# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:54:43.773573Z","iopub.execute_input":"2025-01-09T17:54:43.774945Z","iopub.status.idle":"2025-01-09T17:54:51.033518Z","shell.execute_reply.started":"2025-01-09T17:54:43.774903Z","shell.execute_reply":"2025-01-09T17:54:51.032840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# AE-MLP with Dropout & L2-regulirization\nclass AE_MLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim=128, output_dim=1, dropout_rate=0.3):\n        super(AE_MLP, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(p=dropout_rate),  # Dropout after activation not to overfit\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(p=dropout_rate)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(hidden_dim // 2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(p=dropout_rate),\n            nn.Linear(hidden_dim, output_dim)\n        )\n    \n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n# Взвешенная Huber Loss\ndef weighted_loss(predictions, targets, weights, delta=1.0):\n    loss = nn.SmoothL1Loss(beta=delta, reduction='none')  # Huber Loss\n    per_sample_loss = loss(predictions, targets)\n    weighted_loss = (per_sample_loss * weights).mean()  # weight loss\n    return weighted_loss\n\n    \nae_model = AE_MLP(input_dim=91, hidden_dim=128) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:54:51.034290Z","iopub.execute_input":"2025-01-09T17:54:51.034848Z","iopub.status.idle":"2025-01-09T17:54:51.063793Z","shell.execute_reply.started":"2025-01-09T17:54:51.034823Z","shell.execute_reply":"2025-01-09T17:54:51.062758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ae_model.load_state_dict(torch.load('/kaggle/input/ae_mlp_js24_v2/pytorch/ae_mlp_js24_v2/1/ae_mlp_model_06_01_2025.pth', weights_only=True))\n# ae_model.eval()\nae_model.to('cuda:0')\nscaler = load('/kaggle/input/scaler_new/other/scaler_new/1/robust_scaler_07_01.pkl')","metadata":{"execution":{"iopub.status.busy":"2025-01-09T17:55:25.527663Z","iopub.execute_input":"2025-01-09T17:55:25.527989Z","iopub.status.idle":"2025-01-09T17:55:25.606391Z","shell.execute_reply.started":"2025-01-09T17:55:25.527964Z","shell.execute_reply":"2025-01-09T17:55:25.605787Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CONFIG:\n    seed = 42\n    target_col = \"responder_6\"\n    feature_cols_ae_mlp = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n    feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)]+[\"responder_6_lag_1\"]\n    #[f\"responder_{idx}_lag_1\" for idx in range(9)]\n    \nxgb_feature_cols = [\"date_id\", \"time_id\", \"symbol_id\"] + CONFIG.feature_cols\nae_mlp_cols =[f\"feature_{idx:02d}\" for idx in range(79)] + [f\"responder_{idx}_lag_1\" for idx in range(9)] + ['symbol_id', 'time_id', 'date_id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:54:51.094057Z","iopub.execute_input":"2025-01-09T17:54:51.094342Z","iopub.status.idle":"2025-01-09T17:54:51.100063Z","shell.execute_reply.started":"2025-01-09T17:54:51.094313Z","shell.execute_reply":"2025-01-09T17:54:51.099345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# lags_ : pl.DataFrame | None = None\n    \n# def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n#     global lags_\n#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#     ae_model.to(device)\n    \n#     if lags is not None:\n#         lags_ = lags\n\n#     predictions = test.select(\n#         'row_id',\n#         pl.lit(0.0).alias('responder_6'),\n#     )\n#     symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n\n#     if not lags is None:\n#         lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n#         features_lags = [\"date_id\", \"symbol_id\"]+[f\"responder_{idx}_lag_1\" for idx in range(9)]\n#         lags = lags[features_lags]\n#         test = test.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n#     else:\n#         test = test.with_columns(\n#             ( pl.lit(0.0).alias(f'responder_6_lag_1'))\n#         )\n\n#     preds = np.zeros((test.shape[0],))\n#     test_input = test[ae_mlp_cols].to_pandas()\n#     test_input = test_input.ffill().fillna(0)\n#     test_input = torch.FloatTensor(test_input.values).to(device)\n    \n#     with torch.no_grad():\n#         ae_model.eval()\n#         # Перемещаем входные данные на правильное устройство\n#         test_input = test_input.to(device)\n#         preds = ae_model(test_input).to(\"cpu\").numpy().flatten()  # Возвращаем на \n        \n#     print(f\"predict> preds.shape =\", preds.shape)\n#     # print(f\"preds.shape: {preds.shape}, test.shape: {test.shape}\")\n    \n#     predictions = test.select('row_id').with_columns(\n#     pl.Series(\n#         name='responder_6',\n#         values=np.clip(preds, a_min=-5, a_max=5).astype(np.float64),\n#         dtype=pl.Float64,\n#     )\n# )\n\n\n#     # The predict function must return a DataFrame\n#     assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n#     # with columns 'row_id', 'responer_6'\n#     assert list(predictions.columns) == ['row_id', 'responder_6']\n#     # and as many rows as the test data.\n#     assert len(predictions) == len(test)\n#     assert len(preds) == len(test)\n\n#     return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:54:51.100933Z","iopub.execute_input":"2025-01-09T17:54:51.101222Z","iopub.status.idle":"2025-01-09T17:54:51.118711Z","shell.execute_reply.started":"2025-01-09T17:54:51.101189Z","shell.execute_reply":"2025-01-09T17:54:51.117856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n#     global lags_\n#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#     ae_model.to(device)\n    \n#     if lags is not None:\n#         lags_ = lags\n\n#     predictions = test.select(\n#         'row_id',\n#         pl.lit(0.0).alias('responder_6'),\n#     )\n\n#     if not lags is None:\n#         lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()\n#         # lags = lags_.clone().group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()\n#         features_lags = [\"date_id\", \"symbol_id\"] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n#         lags = lags[features_lags]\n#         test = test.join(lags, on=[\"date_id\", \"symbol_id\"], how=\"left\")\n#     else:\n#         test = test.with_columns(\n#             pl.lit(0.0).alias(f'responder_6_lag_1')\n#         )\n\n#     # Apply the RobustScaler to the feature columns (X)\n#     test_input = test[ae_mlp_cols].to_pandas()\n#     test_input = test_input.ffill().fillna(0)  # Fill missing values (if any)\n\n#     # Apply the robust scaler to the input features\n#     test_input_scaled = scaler.transform(test_input.values)  # Apply scaling to the input features\n\n#     # Convert scaled data to a tensor for model input\n#     test_input_tensor = torch.FloatTensor(test_input_scaled).to(device)\n    \n#     # Predict using the model\n#     with torch.no_grad():\n#         ae_model.eval()\n#         preds = ae_model(test_input_tensor).to(\"cpu\").numpy().flatten()\n\n#     print(f\"predict> preds.shape = {preds.shape}\")\n    \n#     predictions = test.select('row_id').with_columns(\n#         pl.Series(\n#             name='responder_6',\n#             values=np.clip(preds, a_min=-5, a_max=5).astype(np.float64),\n#             dtype=pl.Float64,\n#         )\n#     )\n\n#     # Check assertions for correct output\n#     assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n#     assert list(predictions.columns) == ['row_id', 'responder_6']\n#     assert len(predictions) == len(test)\n#     assert len(preds) == len(test)\n\n#     return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:54:51.120440Z","iopub.execute_input":"2025-01-09T17:54:51.120664Z","iopub.status.idle":"2025-01-09T17:54:51.134531Z","shell.execute_reply.started":"2025-01-09T17:54:51.120645Z","shell.execute_reply":"2025-01-09T17:54:51.133692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Global variable to store lagged features\nlags_: pl.DataFrame | None = None\n\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"\n    Make predictions using ensemble of XGBoost and Neural Network models\n    \n    Args:\n        test: DataFrame containing test data\n        lags: DataFrame containing lagged features (optional)\n        \n    Returns:\n        DataFrame with predictions\n    \"\"\"\n    global lags_\n    \n    # Store lags in global variable if provided\n    if lags is not None:\n        lags_ = lags\n\n    # Initialize predictions DataFrame with row_id and placeholder predictions\n    predictions_nn = test.select('row_id', pl.lit(0.0).alias('responder_6',))\n\n    # Process lagged features\n    # Get last record for each date_id and symbol_id combination\n    lags = lags_.clone().group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()\n    \n    # Join test data with lagged features\n    test = test.join(lags, on=[\"date_id\", \"symbol_id\"], how=\"left\")\n    preds_nn = np.zeros((test.shape[0],))   # Neural Network predictions\n\n    # Generate Neural Network predictions\n    # Prepare input data\n    test_input = test[ae_mlp_cols].to_pandas()\n    # Handle missing values: forward fill then fill remaining with zeros\n    test_input = test_input.fillna(method='ffill').fillna(0)\n    test_input = scaler.transform(test_input.values)\n    # Convert to PyTorch tensor and move to GPU\n    test_input = torch.FloatTensor(test_input).to(\"cuda:0\")\n\n    # Generate predictions from Neural Network ensemble\n    with torch.no_grad():  # Disable gradient calculation for inference\n        ae_model.eval()  # Set model to evaluation mode\n        # Average predictions from all models\n        preds_nn = ae_model(test_input).cpu().numpy().flatten()\n\n\n    # Create final predictions DataFrame\n    predictions_nn = test.select('row_id').\\\n        with_columns(\n            pl.Series(\n                name='responder_6',\n                values=np.clip(preds_nn, a_min=-5, a_max=5),  # Clip predictions to [-5, 5] range\n                dtype=pl.Float64,\n            )\n        )\n    \n    return predictions_nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:54:51.135574Z","iopub.execute_input":"2025-01-09T17:54:51.135904Z","iopub.status.idle":"2025-01-09T17:54:51.149474Z","shell.execute_reply.started":"2025-01-09T17:54:51.135864Z","shell.execute_reply":"2025-01-09T17:54:51.148723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:55:29.756642Z","iopub.execute_input":"2025-01-09T17:55:29.756953Z","iopub.status.idle":"2025-01-09T17:55:29.965841Z","shell.execute_reply.started":"2025-01-09T17:55:29.756929Z","shell.execute_reply":"2025-01-09T17:55:29.964833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
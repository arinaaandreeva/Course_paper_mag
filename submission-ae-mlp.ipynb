{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":169851,"sourceType":"modelInstanceVersion","modelInstanceId":144507,"modelId":167068},{"sourceId":169928,"sourceType":"modelInstanceVersion","modelInstanceId":144567,"modelId":167129},{"sourceId":169990,"sourceType":"modelInstanceVersion","modelInstanceId":144620,"modelId":167181},{"sourceId":191664,"sourceType":"modelInstanceVersion","modelInstanceId":163370,"modelId":185731},{"sourceId":191687,"sourceType":"modelInstanceVersion","modelInstanceId":163391,"modelId":185754},{"sourceId":191903,"sourceType":"modelInstanceVersion","modelInstanceId":163595,"modelId":185954},{"sourceId":191938,"sourceType":"modelInstanceVersion","modelInstanceId":163630,"modelId":185989},{"sourceId":205603,"sourceType":"modelInstanceVersion","modelInstanceId":175344,"modelId":197693},{"sourceId":205605,"sourceType":"modelInstanceVersion","modelInstanceId":175346,"modelId":197695},{"sourceId":206072,"sourceType":"modelInstanceVersion","modelInstanceId":175730,"modelId":198074},{"sourceId":220368,"sourceType":"modelInstanceVersion","modelInstanceId":187942,"modelId":209985}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom joblib import load\nimport polars as pl\nimport kaggle_evaluation.jane_street_inference_server\nimport gc\nimport lightgbm as lgb\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, WeightedRandomSampler, TensorDataset\nfrom tqdm.auto import tqdm\n# import tensorflow as tf\n# from tensorflow.keras import layers, models\n\nimport os\n# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# AE-MLP with Dropout & L2-regulirization\nclass AE_MLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim=128, output_dim=1, dropout_rate=0.3):\n        super(AE_MLP, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(p=dropout_rate),  # Dropout after activation not to overfit\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(p=dropout_rate)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(hidden_dim // 2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(p=dropout_rate),\n            nn.Linear(hidden_dim, output_dim)\n        )\n    \n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n# Взвешенная Huber Loss\ndef weighted_loss(predictions, targets, weights, delta=1.0):\n    loss = nn.SmoothL1Loss(beta=delta, reduction='none')  # Huber Loss\n    per_sample_loss = loss(predictions, targets)\n    weighted_loss = (per_sample_loss * weights).mean()  # weight loss\n    return weighted_loss\n\n    \nae_model = AE_MLP(input_dim=91, hidden_dim=128) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:58:34.557289Z","iopub.execute_input":"2025-01-06T06:58:34.557655Z","iopub.status.idle":"2025-01-06T06:58:34.568016Z","shell.execute_reply.started":"2025-01-06T06:58:34.557628Z","shell.execute_reply":"2025-01-06T06:58:34.566818Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"ae_model.load_state_dict(torch.load('/kaggle/input/ae_mlp_js24_v2/pytorch/ae_mlp_js24_v2/1/ae_mlp_model_06_01_2025.pth', weights_only=True))\n# ae_model.eval()\nscaler = load('/kaggle/input/robust_scaler/scikitlearn/robust_scaler/1/robust_scaler.pkl')","metadata":{"execution":{"iopub.status.busy":"2025-01-06T06:58:36.143757Z","iopub.execute_input":"2025-01-06T06:58:36.144110Z","iopub.status.idle":"2025-01-06T06:58:36.155692Z","shell.execute_reply.started":"2025-01-06T06:58:36.144085Z","shell.execute_reply":"2025-01-06T06:58:36.154714Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"class CONFIG:\n    seed = 42\n    target_col = \"responder_6\"\n    feature_cols_ae_mlp = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n    feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)]+[\"responder_6_lag_1\"]\n    #[f\"responder_{idx}_lag_1\" for idx in range(9)]\n    \nxgb_feature_cols = [\"date_id\", \"time_id\", \"symbol_id\"] + CONFIG.feature_cols\nae_mlp_cols =[\"date_id\"] +  CONFIG.feature_cols_ae_mlp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:58:36.309813Z","iopub.execute_input":"2025-01-06T06:58:36.310144Z","iopub.status.idle":"2025-01-06T06:58:36.315586Z","shell.execute_reply.started":"2025-01-06T06:58:36.310118Z","shell.execute_reply":"2025-01-06T06:58:36.314548Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# lags_ : pl.DataFrame | None = None\n    \n# def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n#     global lags_\n#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#     ae_model.to(device)\n    \n#     if lags is not None:\n#         lags_ = lags\n\n#     predictions = test.select(\n#         'row_id',\n#         pl.lit(0.0).alias('responder_6'),\n#     )\n#     symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n\n#     if not lags is None:\n#         lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n#         features_lags = [\"date_id\", \"symbol_id\"]+[f\"responder_{idx}_lag_1\" for idx in range(9)]\n#         lags = lags[features_lags]\n#         test = test.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n#     else:\n#         test = test.with_columns(\n#             ( pl.lit(0.0).alias(f'responder_6_lag_1'))\n#         )\n\n#     preds = np.zeros((test.shape[0],))\n#     test_input = test[ae_mlp_cols].to_pandas()\n#     test_input = test_input.ffill().fillna(0)\n#     test_input = torch.FloatTensor(test_input.values).to(device)\n    \n#     with torch.no_grad():\n#         ae_model.eval()\n#         # Перемещаем входные данные на правильное устройство\n#         test_input = test_input.to(device)\n#         preds = ae_model(test_input).to(\"cpu\").numpy().flatten()  # Возвращаем на \n        \n#     print(f\"predict> preds.shape =\", preds.shape)\n#     # print(f\"preds.shape: {preds.shape}, test.shape: {test.shape}\")\n    \n#     predictions = test.select('row_id').with_columns(\n#     pl.Series(\n#         name='responder_6',\n#         values=np.clip(preds, a_min=-5, a_max=5).astype(np.float64),\n#         dtype=pl.Float64,\n#     )\n# )\n\n\n#     # The predict function must return a DataFrame\n#     assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n#     # with columns 'row_id', 'responer_6'\n#     assert list(predictions.columns) == ['row_id', 'responder_6']\n#     # and as many rows as the test data.\n#     assert len(predictions) == len(test)\n#     assert len(preds) == len(test)\n\n#     return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:08:50.550525Z","iopub.execute_input":"2025-01-06T07:08:50.550998Z","iopub.status.idle":"2025-01-06T07:08:50.561034Z","shell.execute_reply.started":"2025-01-06T07:08:50.550963Z","shell.execute_reply":"2025-01-06T07:08:50.559913Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    global lags_\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    ae_model.to(device)\n    \n    if lags is not None:\n        lags_ = lags\n\n    predictions = test.select(\n        'row_id',\n        pl.lit(0.0).alias('responder_6'),\n    )\n\n    if not lags is None:\n        lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()\n        features_lags = [\"date_id\", \"symbol_id\"] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n        lags = lags[features_lags]\n        test = test.join(lags, on=[\"date_id\", \"symbol_id\"], how=\"left\")\n    else:\n        test = test.with_columns(\n            pl.lit(0.0).alias(f'responder_6_lag_1')\n        )\n\n    # Apply the RobustScaler to the feature columns (X)\n    test_input = test[ae_mlp_cols].to_pandas()\n    test_input = test_input.ffill().fillna(0)  # Fill missing values (if any)\n\n    # Apply the robust scaler to the input features\n    test_input_scaled = scaler.transform(test_input)  # Apply scaling to the input features\n\n    # Convert scaled data to a tensor for model input\n    test_input_tensor = torch.FloatTensor(test_input_scaled).to(device)\n    \n    # Predict using the model\n    with torch.no_grad():\n        ae_model.eval()\n        preds = ae_model(test_input_tensor).to(\"cpu\").numpy().flatten()\n\n    print(f\"predict> preds.shape = {preds.shape}\")\n    \n    predictions = test.select('row_id').with_columns(\n        pl.Series(\n            name='responder_6',\n            values=np.clip(preds, a_min=-5, a_max=5).astype(np.float64),\n            dtype=pl.Float64,\n        )\n    )\n\n    # Check assertions for correct output\n    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n    assert list(predictions.columns) == ['row_id', 'responder_6']\n    assert len(predictions) == len(test)\n    assert len(preds) == len(test)\n\n    return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:10:58.369989Z","iopub.execute_input":"2025-01-06T07:10:58.370321Z","iopub.status.idle":"2025-01-06T07:10:58.381119Z","shell.execute_reply.started":"2025-01-06T07:10:58.370295Z","shell.execute_reply":"2025-01-06T07:10:58.379828Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:10:58.713371Z","iopub.execute_input":"2025-01-06T07:10:58.713785Z","iopub.status.idle":"2025-01-06T07:10:58.755523Z","shell.execute_reply.started":"2025-01-06T07:10:58.713753Z","shell.execute_reply":"2025-01-06T07:10:58.754513Z"}},"outputs":[{"name":"stdout","text":"predict> preds.shape = (39,)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}